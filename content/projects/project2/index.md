---
title: "Роботы"
tags: ["Pytorch","ML","CS","JAX", "C"]
author: ["Огородников Даниил"]
description: "world model" 
summary: "агент обучается управлять роботом, почти не взаимодействуя с реальной средой" 
cover:
    image: "text2action.png"
    #alt: "Some Uses For Olive Oil"
    relative: true

---
---
![](text2action.png)

---
##### Ссылки

+ [текст работы](robots.pdf)

---
#### Интро
Создание надёжных систем управления для роботов традиционно требует месяцев экспертной работы, сложного программирования и миллионов взаимодействий со средой.  
Я предлагаю радикально иной путь: агент обучается управлять роботом, почти не взаимодействуя с реальной средой.
Ключевая идея — перенести всю сложность в мощную внутреннюю модель мира, а сам контроллер оставить предельно простым.

#### Задача
Научить робота выполнять сложные манипуляционные задачи (например, аккуратно сложить ткань в контейнер, собрать объект из деталей и т. д.) в условиях:
- высокомерных визуальных наблюдений (кадры с камер);
- редкого или отложенного вознаграждения;
- необходимости быстрого развёртывания на новых роботах и в новых средах.
- 
#### Основные сложности
- Проблема credit assignment в классическом RL при длинных эпизодах;
- Огромное время обучения (10⁶–10⁹ шагов взаимодействия со средой);
- Плохая переносимость (sim-to-real gap) при обучении только в симуляторе;
- Необходимость переобучения под каждую новую задачу.

#### Мой подход
1. Без учителя обучаю большую универсальную модель мира:
    - VAE — сжатие каждого кадра в низкоразмерный вектор zₜ (64–128 dim);
    - MDN-RNN — предсказание распределения следующего zₜ₊₁ по текущему zₜ, скрытому состоянию hₜ и действию aₜ.
2. Модель мира обучается на огромных офлайн-видеодатасетах (Ego4D + DROID, >4000 часов), без какого-либо сигнала reward.
3. Контроллер — однослойная линейная сеть (~867 параметров), принимающая на вход только [zₜ, hₜ] → aₜ.
4. Контроллер обучается исключительно внутри rollout-ов, сгенерированных собственной моделью мира (полная замена реальной среды).
5. Для предотвращения переобучения на артефакты модели используется повышенная температура сэмплирования.

Итог: вся «тяжёлая» часть (понимание мира) — универсальна и обучается один раз.  
Политика управления — крошечная, обучается за 10⁴ шагов и сразу работает в реальности (zero-shot sim-to-real).

#### Успехи
- Обучение политики за ~10⁴ шагов вместо 10⁶–10⁹;
- Достигнута точность 0.66 при потерях 0.07 (лучше аналогов);
- Успешный zero-shot перенос из полностью сгенерированной среды в реальную;
- Универсальность: одна модель мира используется для совершенно разных задач без дообучения;

#### Дорабатываю
- Иерархические контроллеры (добавить второй уровень для планирования на 5–10 сек);
- Интеграция тактильных и проприоцептивных модальностей в латентное пространство;
- Тестирование на более широком наборе реальных роботов (Franka Emika, UR5e, Shadow Hand);
- Открытие кода и предобученных моделей мира (в процессе).