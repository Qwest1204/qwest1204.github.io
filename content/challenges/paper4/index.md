---
title: "НТО что тут ещё сказать" 
date: 2025-11-10
tags: ["NTO", "ML", "Data", "Book"]
author: ["Даниил Огородников"]
description: "" 
summary: "Трек «Искусственный интеллект» · профиль «Рекомендательные системы и генеративные модели»" 
cover:
    image: "paper4.png"
    alt: ""
    relative: true

---

---


##### инторо

Сейчас я в составе команды участвую в НТО — это самый масштабный российский инженерный чемпионат для школьников 8–11 классов и студентов колледжей. Наш трек посвящён рекомендательным системам, и задача в этом году невероятно крутая и близка к реальным продуктовым задачам крупных книжных/контентных платформ.

##### Суть задачи
Есть книжная платформа, где пользователи могут:

* добавить книгу в «планы» (has_read = 0) — слабый сигнал интереса;
* отметить, что действительно прочитали (has_read = 1) — сильный сигнал.

Нужно построить модель, которая для каждого пользователя правильно упорядочит список из ~100–200 книг-кандидатов по трёхуровневой ценности:
- 2 балла → уже прочитанные книги (должны быть строго сверху)
- 1 балл → добавленные в планы, но не прочитанные
- 0 баллов → «холодные» кандидаты (книги, с которыми пользователь никогда не взаимодействовал, но которые подкинула базовая модель рекомендаций)
По сути — это Learning-to-Rank задача с очень чёткой иерархией релевантности + предсказание конверсии «намерение → действие».

#### Что уже сделано на текущий момент

- Прошли индивидуальный отборочный этап (топ-20 % по треку).
- Сейчас идёт командный этап: строим двухстадийную модель:
- Классификатор/регрессор, который предсказывает вероятность has_read = 1 и силу сигнала.
- LTR-модель (LightGBM Ranker / CatBoost с pairwise и listwise лоссами), которая учится именно на правильном порядке.

Экспериментируем с признаками: эмбеддинги книг из BERT/RuBERTa, статистика по автору/жанру/издательству, временны́е фичи (давность взаимодействия, скорость чтения пользователя), «температура» пользователя (насколько часто он доводит планы до прочтения) и т.д.